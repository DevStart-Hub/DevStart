---
title: "Create an eye-tracking experiment"
date: "05/20/2024"
execute:
  eval: false
jupyter:
  kernel: "python3"
author-meta: "Tommaso Ghilardi, Francesco Poli"
description-meta: "Learn how to record eyetracking data in your psychopy experiment using Tobii SDK, tobii_research"
keywords: "PsychoPy, Python, eye-tracking, tobii, tobii_research, experimental psychology, tutorial, experiment, DevStart, developmental science"
categories:
  - Eye-tracking
  - Python
---

This page will show you how to collect eye-tracking data in a simple Psychopy paradigm. We will use the same paradigm that we built together in the [Getting started with Psychopy](/CONTENT/GettingStarted/GettingStartedWithPsychopy.qmd) tutorial. If you have not done that tutorial yet, please go through it first.

::: callout-caution
**Tobii eye-tracker**

Note that this tutorial is specific for using **Tobii eye-trackers**. The general steps and idea are obviously applicable to other eye-trackers, but the specific code and packages may vary.
:::

# Tobii_sdk

To start, we will look into how to connect and talk to our Tobii eyetracker with the **SDK** that Tobii provides. An **SDK** is a collection of tools and programs for developing applications for a specific platform or device. We will use the **Python Tobii SDK** that lets us easily find and get data from our Tobii eye tracker.

## Install

To install the Python Tobii SDK, we can simply run this command in our conda terminal:

``` bash
pip install tobii_research
```

:::: {.info-box .info-box-large}
::: info-box-title
Compatibility older eye-trackers
:::

If you're using an older Tobii eye-tracker, check the compatibility page to see which version of tobii_research you need for your specific model. Check it [here](https://developer.tobiipro.com/tobiiprosdk/eyetrackercompatibility.html).
::::

Great! We have installed the Tobii SDK.

## Connect to the eye-tracker

So how does this library work, how do we connect to the eye-tracker and collect our data? Very good questions!

The `tobii_research` documentation is quite extensive and describes in detail a lot of functions and data classes that are very useful. However, we don't need much to start our experiment.

First we need to identify all the eye trackers connected to our computer. Yes, plural, `tobii_research` will return a list of all the eye trackers connected to our computer. 99.99999999% of the time you will only have 1 eye tracker connected, so we can just select the first (and usually only) eye tracker found.

```{python}
# Import tobii_research library
import tobii_research as tr

# Find all connected eye trackers
found_eyetrackers = tr.find_all_eyetrackers()

# We will just use the first one
Eyetracker = found_eyetrackers[0]
```

Perfect!! We have identified our eye-trackers, and we have selected the first one (and only).

We are now ready to use our eye-tracker to collect some data... but how?

## Collect data

Tobii_research has a cool way of telling us what data we are collecting at each time point. It uses a callback function. What is a callback function, you ask? It is a function that tobii runs each time it has a new data point. Let's say we have an eye tracker that collects data at 300Hz (300 samples per second): the function will be called every time the tobii has one of those 300 samples.

This callback function will give us a `gaze_data` dictionary. This dictionary contains multiple information of that collected sample

Here is our callback function:

```{python}
# callback function
def gaze_data_callback(gaze_data):
    print(gaze_data)
```

This will print the entire dictionary to your console. Here's what you'll see:

``` python
{'device_time_stamp': 467525500,
 'system_time_stamp': 6405415231,
 'left_gaze_point_on_display_area': (0.4633694291, 0.4872185290),
 'left_gaze_point_in_user_coordinate_system': (-10.15791702, 128.29026794, 40.876254),
 'left_gaze_point_validity': 1,
 'left_pupil_diameter': 5.655228,
 'left_pupil_validity': 1,
 'left_gaze_origin_in_user_coordinate_system': (-25.86829758, 1.41938722, 644.839478),
 'left_gaze_origin_in_trackbox_coordinate_system': (0.561557, 0.481128, 0.489121),
 'left_gaze_origin_validity': 1,
 'right_gaze_point_on_display_area': (0.4944303632, 0.4498708546),
 'right_gaze_point_in_user_coordinate_system': (0.7905667424, 135.2486572266, 43.373546),
 'right_gaze_point_validity': 1,
 'right_pupil_diameter': 5.307220,
 'right_pupil_validity': 1,
 'right_gaze_origin_in_user_coordinate_system': (32.52792358398, -2.97285223007, 640.345520),
 'right_gaze_origin_in_trackbox_coordinate_system': (0.431783, 0.495703, 0.483452),
 'right_gaze_origin_validity': 1}
```

Wow! Look at all that data from just one sample!

Now we need to tell the eye tracker to actually use our callback function. This part is super easy:

```{python}
# Start the callback function
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```

What we're doing here is subscribing to the `EYETRACKER_GAZE_DATA` stream and telling it to send all that data to our `gaze_data_callback` function. Once this runs, your console will start flooding with data!

### Global to save

Great! You've set up a callback function that receives eye tracking data from your device. However, printing 300 data points per second to the console creates an unreadable stream of text that's not useful for analysis. We need to store this data properly.

Let's create a list to collect all the gaze data:

```{python}
# Create an empty list we will append our data to
gaze_data_buffer = []
```

Perfect! We've got our list to which we can append the incoming data. We can simply have this list inside of our callback function so every time an new sample appears it will be added there. This is how our script could look now:

```{python}
# callback function
def gaze_data_callback(gaze_data):
    global gaze_data_buffer
    gaze_data_buffer.append(gaze_data)


# Create an empty list we will append our data to
gaze_data_buffer = []

# Start the callback function
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback, as_dictionary=True)
```

Notice the `global` keyword in the callback function. This tells Python that we want to use the `gaze_data_buffer` variable that was created outside the function. Without this keyword, Python may create a new local variable instead of using our existing list.

Now instead of flooding the console, every new sample gets stored in our list for later analysis!

## Triggers/Events

As we have seen, our callback function can access the tobii data and tell us what it is for each sample. Just one little piece missing... We want to know what we presented and when. In most studies, we present stimuli that can be pictures, sounds or even videos. For the following analysis, it is important to know at what exact point in time we presented these stimuli.

The Tobii SDK provides an elegant solution through the `tr.get_system_time_stamp()` function. This function returns the current time from the system clock. And if you paid attention between the information the eyetrcker is passing us one of them is the `system_time_stamp`. So we can create a simple event-logging system by storing timestamps along with descriptive event labels.

We first create an empty list called Events and we append the time from the system and a description of what is happening every time we need. Just like so:

```{python}
Events = [] # create empty list

# Get the current time from the eye-tracker's clock
Events.append({'system_time_stamp':  tr.get_system_time_stamp(), 'label': 'Our First event!!'})
```

## Save the data

Perfect! We have two lists with all our information. They grow bigger and bigger (especially the gaze_data_buffer) and we need a way to save them. There are two approaches we could use:

1.  Save data inside our callback function, appending new data to a CSV each time the callback is called.

2.  Collect all data in lists for the entire study duration, then save everything at the end.

However, both approaches have drawbacks. The first option might slow down our callback function if our computer isn't performing well or if we're sampling at very high rates. The second approach won't create bottlenecks for the callback, but if something goes wrong during the study and Python crashes (and trust me, it can happen!!), we'd lose all our precious data.

**The solution? A hybrid approach!** We store our data in lists and save them during quieter moments of our study - like during the Inter-Stimulus Interval (ISI), the pause between trials. This time is typically meant to give participants a brief rest, making it perfect for our data-saving operations.

Now we need to save our data efficiently. The key challenge is avoiding duplicate data - we don't want to save the same samples multiple times when we call our save function repeatedly.

Our solution is simple: **track how many samples we've already saved, then only process the new ones each time.**

Here's how it works:

-   Keep a counter of samples already processed

-   Use list slicing to get only new data since last save

-   Process and save the new data

-   Update our counter

```{python}
# Initial data saved counter starting at 0
data_saved_count = 0

# Get only new data since last save
new_data = gaze_data_buffer[data_saved_count:]

# Create a dataframe from our data
Data_df = pd.DataFrame(new_data)

# update the data saved counter
data_saved_count += len(new_data)
```

Before actually saving this dataframe, let's add our events to it! This way we'll have one unified dataframe with all our data and events. Sounds amazing, right?

We'll follow the same approach for events:

```{python}
# Initial event saved counter starting at 0
events_saved_count = 0

# Create a dataframe from our events
new_events = Events[events_saved_count:]

Events_df = pd.DataFrame(new_events)     

# update the data saved counter
events_saved_count += len(new_events)
```

Perfect! Now we have two dataframes. Next, we need to align the events with the data. We'll use numpy's `searchsorted` function to find the closest timestamp in our data for each event, then add the event labels at the correct positions.

```{python}
# Find the index for each event in the dataframe
idx = np.searchsorted(Data_df['system_time_stamp'].values,
                      Events_df['system_time_stamp'].values,
                      side='left')

# Add the events to the dataframe
Data_df['events'] = ''
Data_df.loc[idx, 'events'] = Events_df['label'].values    
```

This wasn't so hard, was it?

But I would suggest wrapping this in a function so you can call it whenever you want to save data:

```{python}
# Global counters
# Track how many samples we've already saved
data_saved_count = 0
events_saved_count = 0

# Function to save data
def write_buffer_to_file(data_to_save, events_to_save, filename):
    global data_saved_count, events_saved_count
   
    # Get only new data since last save
    new_data = data_to_save[data_saved_count:]
    new_events = events_to_save[events_saved_count:]
   
    # Create data and event dataframes
    data_df = pd.DataFrame(new_data)
    events_df = pd.DataFrame(new_events)
   
    # Find where each event is in the dataframe
    idx = np.searchsorted(data_df['system_time_stamp'].values,
                          events_df['system_time_stamp'].values,
                          side='left')
    
    # Add the events to the dataframe
    data_df['events'] = ''
    data_df.loc[idx, 'events'] = events_df['label'].values
   
    # Write the DataFrame to a csv file
    data_df.to_csv(filename, mode='a', index=False, header=not os.path.isfile(filename))
   
    # Update counters
    data_saved_count += len(new_data)
    events_saved_count += len(new_events)
```

This function takes three inputs: your gaze data buffer, your events buffer, and the desired CSV filename. The `mode='a'` parameter tells pandas to append new data to the end of an existing file rather than overwriting it. This is perfect for our incremental saving approach since each time we save, we add new rows to our growing CSV file instead of losing previous data.

The `header=not os.path.isfile(filename)` part is a clever trick that writes column headers only when creating a new file. This prevents duplicate headers from appearing throughout your data file every time you save.

::: callout-note
You could also save gaze data and events as separate CSV files during collection, then align and merge them during analysis.

However, we prefer combining them immediately for two reasons: it eliminates an extra step later, and it creates cleaner data files for the upcoming tutorials. Both approaches are perfectly valid - choose whichever fits your workflow better. If you're just starting out, combining them now will make your life easier down the road.
:::

## Clean and Prepare Your Data

Great! Now you know how to collect eye tracking data and save it to a file with events in the same dataframe. Let's add a few optional steps that will make your data much easier to analyze and give you better insights into what we're working with.

### Split Gaze Coordinates into Separate Columns

When we convert gaze data to a pandas DataFrame, coordinate pairs like `'left_gaze_point_on_display_area': (0.4633694291, 0.4872185290)` become single columns containing tuples. This creates analysis headaches - you can't easily filter, plot, or perform calculations on x and y values when they're bundled together. Instead, we want separate columns for x and y coordinates for both eyes.

Let's add this to our save function:

```{python}
# Global counters
data_saved_count = 0
events_saved_count = 0

def write_buffer_to_file(data_to_save, events_to_save, filename):
    global data_saved_count, events_saved_count
   
    # Get only new data since last save
    new_data = data_to_save[data_saved_count:]
    new_events = events_to_save[events_saved_count:]
   
    # Create dataframes
    data_df = pd.DataFrame(new_data)
    events_df = pd.DataFrame(new_events)
   
    # Align events with data
    idx = np.searchsorted(data_df['system_time_stamp'].values,
                          events_df['system_time_stamp'].values,
                          side='left')
    data_df['events'] = ''
    data_df.loc[idx, 'events'] = events_df['label'].values
    
    #### Split coordinate tuples into separate columns
    data_df[['left_x', 'left_y']] = data_df['left_gaze_point_on_display_area'].tolist()
    data_df[['right_x', 'right_y']] = data_df['right_gaze_point_on_display_area'].tolist()

    # Save to CSV
    data_df.to_csv(filename, mode='a', index=False, header=not os.path.isfile(filename))
   
    # Update counters
    data_saved_count += len(new_data)
    events_saved_count += len(new_events)
```

Perfect!! Well done!! Now we have two columns for x and y coordinates for both eyes

### Adjust the data

The Active Display Coordinate System (ADCS) maps all gaze data onto a 2D coordinate system where (0, 0) represents the upper left corner of the screen, and (1, 1) represents the lower right corner.

While this coordinate system works perfectly, it might cause confusion during analysis and plotting. This is because most plotting systems expect the origin in the lower left corner, not the upper left. The image below illustrates this difference:m

![](/images/CreateAnEyetrackingExperiment/Origins.png){fig-align="center" width="419"}

For this reason, we typically adjust the data to position the origin in the bottom left corner. This can be achieved by subtracting the y-coordinates from 1 (since coordinates range from 0 to 1).

Additionally, we'll make several other useful adjustments:

-   **Convert to pixels**: Gaze coordinates range from 0 to 1, but pixel coordinates are often more convenient for analysis. We multiply by screen dimensions to convert.

-   **Simplify timestamps**: Tobii provides microsecond precision, but milliseconds are usually sufficient. We divide by 1000 for easier handling.

-   **Clean up columns**: We'll rename columns to be more intuitive and keep only the essential data.

Here's our enhanced function:

```{python}
# Global counters  
data_saved_count = 0
events_saved_count = 0

# Screen dimensions (replace with your actual screen size)
winsize = [1920, 1080]  # width, height in pixels

def write_buffer_to_file(data_to_save, events_to_save, filename):
    global data_saved_count, events_saved_count, winsize
   
    # Get only new data since last save
    new_data = data_to_save[data_saved_count:]
    new_events = events_to_save[events_saved_count:]

    # Create dataframes
    data_df = pd.DataFrame(new_data)
    events_df = pd.DataFrame(new_events)
   
    # Align events with data
    idx = np.searchsorted(data_df['system_time_stamp'].values,
                          events_df['system_time_stamp'].values,
                          side='left')
    data_df['events'] = ''
    data_df.loc[idx, 'events'] = events_df['label'].values
    
    #### Split coordinate tuples into separate columns
    data_df[['left_x', 'left_y']] = data_df['left_gaze_point_on_display_area'].tolist()
    data_df[['right_x', 'right_y']] = data_df['right_gaze_point_on_display_area'].tolist()
    
    #### Convert and adjust coordinates
    data_df['time'] = data_df['system_time_stamp'] / 1000.0
    data_df['left_x'] = data_df['left_x'] * winsize[0]
    data_df['left_y'] = winsize[1] - data_df['left_y'] * winsize[1]  # Flip y-axis
    data_df['right_x'] = data_df['right_x'] * winsize[0]
    data_df['right_y'] = winsize[1] - data_df['right_y'] * winsize[1]  # Flip y-axis
    
    #### Rename columns for clarity
    data_df = data_df.rename(columns={
        'left_gaze_point_validity': 'left_valid',
        'right_gaze_point_validity': 'right_valid',
        'left_pupil_diameter': 'left_pupil',
        'right_pupil_diameter': 'right_pupil',
        'left_pupil_validity': 'left_pupil_valid',
        'right_pupil_validity': 'right_pupil_valid'
    })
    
    # Keep only essential columns
    data_df = data_df[['time', 'left_x', 'left_y', 'left_valid', 'left_pupil', 'left_pupil_valid',
                       'right_x', 'right_y', 'right_valid', 'right_pupil', 'right_pupil_valid', 'events']]
    
    # Save to CSV
    data_df.to_csv(filename, mode='a', index=False, header=not os.path.isfile(filename))
   
    # Update counters
    data_saved_count += len(new_data)
    events_saved_count += len(new_events)
```

# Create the actual experiment

Now we have two function, one to access and append the data to a list, and the second to save the data to a csv. Let's see now how to include these functions in our study.

## Short recap of the paradigm

As we already mentioned, we will use the experimental design that we created in [Getting started with Psychopy](/CONTENT/GettingStarted/GettingStartedWithPsychopy.qmd) as a base and we will add things to it to make it an eye-tracking study. If you don't remember the paradigm please give it a rapid look as we will not go into much detail about each specific part of it.

Here a very short summary of what the design was: After a fixation cross, two shapes can be presented: a circle or a square. The circle indicates that a reward will appear on the right of the screen while the square predicts the appearance of an empty cloud on the left.

## Combine things

Let's try to build together the experiment then.

### Import and functions

To start, let's import the libraries and define the two functions that we create before

```{python}
import os
from pathlib import Path
import pandas as pd
import numpy as np

# Import some libraries from PsychoPy
from psychopy import core, event, visual, sound

import tobii_research as tr

#%% Functions

# Global counters for tracking saved data
data_saved_count = 0
events_saved_count = 0

# Screen dimensions
winsize = [1920, 1080]  # width, height in pixels

# This will be called every time there is new gaze data
def gaze_data_callback(gaze_data):
    global gaze_data_buffer
    gaze_data_buffer.append(gaze_data)

def write_buffer_to_file(data_to_save, events_to_save, filename):
    global data_saved_count, events_saved_count
   
    # Get only new data since last save
    new_data = data_to_save[data_saved_count:]
    new_events = events_to_save[events_saved_count:]
   
    # Skip if nothing new
    if not new_data:
        return
   
    # Create dataframes
    data_df = pd.DataFrame(new_data)
    events_df = pd.DataFrame(new_events)
   
    # Align events with data
    idx = np.searchsorted(data_df['system_time_stamp'].values,
                          events_df['system_time_stamp'].values,
                          side='left')
    data_df['events'] = ''
    data_df.loc[idx, 'events'] = events_df['label'].values
    
    #### Split coordinate tuples into separate columns
    data_df[['left_x', 'left_y']] = data_df['left_gaze_point_on_display_area'].tolist()
    data_df[['right_x', 'right_y']] = data_df['right_gaze_point_on_display_area'].tolist()
    
    #### Convert and adjust coordinates
    data_df['time'] = data_df['system_time_stamp'] / 1000.0
    data_df['left_x'] = data_df['left_x'] * winsize[0]
    data_df['left_y'] = winsize[1] - data_df['left_y'] * winsize[1]  # Flip y-axis
    data_df['right_x'] = data_df['right_x'] * winsize[0]
    data_df['right_y'] = winsize[1] - data_df['right_y'] * winsize[1]  # Flip y-axis
    
    #### Rename columns for clarity
    data_df = data_df.rename(columns={
        'left_gaze_point_validity': 'left_valid',
        'right_gaze_point_validity': 'right_valid',
        'left_pupil_diameter': 'left_pupil',
        'right_pupil_diameter': 'right_pupil',
        'left_pupil_validity': 'left_pupil_valid',
        'right_pupil_validity': 'right_pupil_valid'
    })
    
    # Keep only essential columns
    data_df = data_df[['time', 'left_x', 'left_y', 'left_valid', 'left_pupil', 'left_pupil_valid',
                       'right_x', 'right_y', 'right_valid', 'right_pupil', 'right_pupil_valid', 'events']]
    
    # Save to CSV
    data_df.to_csv(filename, mode='a', index=False, header=not os.path.isfile(filename))
   
    # Update counters
    data_saved_count += len(new_data)
    events_saved_count += len(new_events)
```

### Load the stimuli

Now we are going to set a few settings, such as the screen size, create a Psychopy window, load the stimuli and then prepare the trial definition. This is exactly the same as we did in the previous Psychopy tutorial.

```{python}
#%% Load and prepare stimuli

# Setting the directory of our experiment
os.chdir(r'<<< YOUR PATH >>>>')

# Now create a Path object for the stimuli directory
stimuli_dir = Path('EXP') / 'Stimuli'

# Create a window
win = visual.Window(size=winsize, fullscr=True, units="pix", pos=(0,30), screen=1)

# Load images 
fixation = visual.ImageStim(win, image=str(stimuli_dir / 'fixation.png'), size=(200, 200))
circle = visual.ImageStim(win, image=str(stimuli_dir / 'circle.png'), size=(200, 200))
square = visual.ImageStim(win, image=str(stimuli_dir / 'square.png'), size=(200, 200))
winning = visual.ImageStim(win, image=str(stimuli_dir / 'winning.png'), size=(200, 200), pos=(250, 0))
losing = visual.ImageStim(win, image=str(stimuli_dir / 'loosing.png'), size=(200, 200), pos=(-250, 0))

# Load sound 
winning_sound = sound.Sound(str(stimuli_dir / 'winning.wav'))
losing_sound = sound.Sound(str(stimuli_dir / 'loosing.wav'))

# List of stimuli
cues = [circle, square] # put both cues in a list
rewards = [winning, losing] # put both rewards in a list
sounds = [winning_sound, losing_sound] # put both sounds in a list

# Create list of trials in which 0 means winning and 1 means losing
Trials = [0, 1, 0, 0, 1, 0, 1, 1, 0, 1]
```

### Start recording

Now we are ready to look for the eye-trackers connected to the computer and select the first one that we find. Once we have selected it, we will launch our callback function to start collecting data.

```{python}
#%% Record the data

# Find all connected eye trackers
found_eyetrackers = tr.find_all_eyetrackers()

# We will just use the first one
Eyetracker = found_eyetrackers[0]

# Create our data buffers
gaze_data_buffer = []
Events = []

# Start recording
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```

### Present our stimuli

The eye-tracking is running! Let's show our participant something!

As you can see below, after each time we flip our window (remember: flipping means we actually show what we drew), we set the trigger variable to a string that identifies the specific stimulus we are presenting. This will be picked up our callback function.

```{python}
#%% Trials
for trial in Trials:

    ### Present the fixation
    win.flip() # we flip to clean the window
    
    fixation.draw()
    win.flip()
    Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Fixation'})
    core.wait(1)  # wait for 1 second

    ### Present the cue
    cues[trial].draw()
    win.flip()
    if trial == 0:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Circle'})
    else:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Square'})
    core.wait(3)  # wait for 3 seconds

    ### Wait for saccadic latency
    win.flip()
    core.wait(0.75)

    ### Present the reward
    rewards[trial].draw()
    win.flip()
    if trial == 0:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Reward'})
    else:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'NoReward'})
    sounds[trial].play()
    core.wait(2)  # wait for 2 seconds
    
    ### ISI
    win.flip()    # we re-flip at the end to clean the window
    clock = core.Clock()
    write_buffer_to_file(gaze_data_buffer, Events, Path('DATA') / 'RAW' / (Sub + '.csv'))
    while clock.getTime() < 1:
        pass
    
    ### Check for closing experiment
    keys = event.getKeys() # collect list of pressed keys
    if 'escape' in keys:
        win.close()  # close window
        Eyetracker.unsubscribe_from(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
        core.quit()  # stop study
```

As we said before in \[Save the data\], it's best to save data during our study to avoid potential data loss. It's better to do this when there are things of minor interest, such as during the ISI. If you remember from the previous tutorial [Getting started with Psychopy](/CONTENT/GettingStarted/GettingStartedWithPsychopy.qmd), we created the ISI in a different way than just using `core.wait()`, and we said that this different method would come in handy later on. This is the moment!

Our ISI starts the clock and saves the data immediately. After saving, we calculate how much time remains to reach the full 1-second duration and use core.wait() for any remaining time. This ensures we wait for exactly 1 second total, accounting for the time spent saving data.

```{python}
### ISI
remaining_time = 1 - clock.getTime()
write_buffer_to_file(gaze_data_buffer, Path('DATA') / 'RAW' / (Sub + '.csv'))
if remaining_time > 0:
    core.wait(remaining_time)
```

::: callout-warning
Careful!!!\
If saving the data takes more than 1 second, your ISI will also be longer. However, this should not be the case with typical studies where trials are not too long. Nonetheless, it's always a good idea to keep an eye out.
:::

### Stop recording

We're almost there! We have imported our functions, started collecting data, sent the triggers, and saved the data. The last step will be stop data collection (or python will keep getting an endless amount of data from the eye tracker!). Do do that, We simply unsubscribe from the eye tracker to which we had subscribed to start of data collection:

```{python}
win.close()
Eyetracker.unsubscribe_from(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```

Note that we also closed the Psychopy window, so that the stimulus presentation is also officially over. Well done!!! Now go and get your data!!! We'll see you back when it's time to analyze it.

# END!!

Great job getting to here!! it want easy but you did it. Here is all the code we made together.

```{python}
import os
from pathlib import Path
import pandas as pd
import numpy as np

# Import some libraries from PsychoPy
from psychopy import core, event, visual, sound

import tobii_research as tr


#%% Functions

# Global counters for tracking saved data
data_saved_count = 0
events_saved_count = 0

# Screen dimensions
winsize = [1920, 1080]  # width, height in pixels

# This will be called every time there is new gaze data
def gaze_data_callback(gaze_data):
    global gaze_data_buffer
    gaze_data_buffer.append(gaze_data)

def write_buffer_to_file(data_to_save, events_to_save, filename):
    global data_saved_count, events_saved_count
   
    # Get only new data since last save
    new_data = data_to_save[data_saved_count:]
    new_events = events_to_save[events_saved_count:]
   
    # Create dataframes
    data_df = pd.DataFrame(new_data)
    events_df = pd.DataFrame(new_events)
   
    # Align events with data
    idx = np.searchsorted(data_df['system_time_stamp'].values,
                          events_df['system_time_stamp'].values,
                          side='left')
    data_df['events'] = ''
    data_df.loc[idx, 'events'] = events_df['label'].values
    
    #### Split coordinate tuples into separate columns
    data_df[['left_x', 'left_y']] = data_df['left_gaze_point_on_display_area'].tolist()
    data_df[['right_x', 'right_y']] = data_df['right_gaze_point_on_display_area'].tolist()
    
    #### Convert and adjust coordinates
    data_df['time'] = data_df['system_time_stamp'] / 1000.0
    data_df['left_x'] = data_df['left_x'] * winsize[0]
    data_df['left_y'] = winsize[1] - data_df['left_y'] * winsize[1]  # Flip y-axis
    data_df['right_x'] = data_df['right_x'] * winsize[0]
    data_df['right_y'] = winsize[1] - data_df['right_y'] * winsize[1]  # Flip y-axis
    
    #### Rename columns for clarity
    data_df = data_df.rename(columns={
        'left_gaze_point_validity': 'left_valid',
        'right_gaze_point_validity': 'right_valid',
        'left_pupil_diameter': 'left_pupil',
        'right_pupil_diameter': 'right_pupil',
        'left_pupil_validity': 'left_pupil_valid',
        'right_pupil_validity': 'right_pupil_valid'
    })
    
    # Keep only essential columns
    data_df = data_df[['time', 'left_x', 'left_y', 'left_valid', 'left_pupil', 'left_pupil_valid',
                       'right_x', 'right_y', 'right_valid', 'right_pupil', 'right_pupil_valid', 'events']]
    
    # Save to CSV
    data_df.to_csv(filename, mode='a', index=False, header=not os.path.isfile(filename))
   
    # Update counters
    data_saved_count += len(new_data)
    events_saved_count += len(new_events)


#%% Load and prepare stimuli

# Setting the directory of our experiment
os.chdir(r'<<< YOUR PATH >>>>')

# Now create a Path object for the stimuli directory
stimuli_dir = Path('EXP') / 'Stimuli'

# Create a window
win = visual.Window(size=winsize, fullscr=True, units="pix", pos=(0,30), screen=1)

# Load images 
fixation = visual.ImageStim(win, image=str(stimuli_dir / 'fixation.png'), size=(200, 200))
circle = visual.ImageStim(win, image=str(stimuli_dir / 'circle.png'), size=(200, 200))
square = visual.ImageStim(win, image=str(stimuli_dir / 'square.png'), size=(200, 200))
winning = visual.ImageStim(win, image=str(stimuli_dir / 'winning.png'), size=(200, 200), pos=(250, 0))
losing = visual.ImageStim(win, image=str(stimuli_dir / 'loosing.png'), size=(200, 200), pos=(-250, 0))

# Load sound 
winning_sound = sound.Sound(str(stimuli_dir / 'winning.wav'))
losing_sound = sound.Sound(str(stimuli_dir / 'loosing.wav'))

# List of stimuli
cues = [circle, square] # put both cues in a list
rewards = [winning, losing] # put both rewards in a list
sounds = [winning_sound, losing_sound] # put both sounds in a list

# Create list of trials in which 0 means winning and 1 means losing
Trials = [0, 1, 0, 0, 1, 0, 1, 1, 0, 1]

#%% Record the data

# Define the subject name
Sub = 'S001'

# Find all connected eye trackers
found_eyetrackers = tr.find_all_eyetrackers()

# We will just use the first one
Eyetracker = found_eyetrackers[0]

# Create our data buffers
gaze_data_buffer = []
Events = []

# Start recording
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)


#%% Trials

for trial in Trials:

    ### Present the fixation
    win.flip() # we flip to clean the window
    
    fixation.draw()
    win.flip()
    Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Fixation'})
    core.wait(1)  # wait for 1 second

    ### Present the cue
    cues[trial].draw()
    win.flip()
    if trial == 0:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Circle'})
    else:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Square'})
    core.wait(3)  # wait for 3 seconds

    ### Wait for saccadic latency
    win.flip()
    core.wait(0.75)

    ### Present the reward
    rewards[trial].draw()
    win.flip()
    if trial == 0:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'Reward'})
    else:
        Events.append({'system_time_stamp': tr.get_system_time_stamp(), 'label': 'NoReward'})

    sounds[trial].play()
    core.wait(2)  # wait for 2 seconds
    
    ### ISI
    win.flip()    # we re-flip at the end to clean the window
    clock = core.Clock()
    write_buffer_to_file(gaze_data_buffer, Events, Path('DATA') / 'RAW' / (Sub + '.csv'))
    while clock.getTime() < 1:
        pass
    
    ### Check for closing experiment
    keys = event.getKeys() # collect list of pressed keys
    if 'escape' in keys:
        win.close()  # close window
        Eyetracker.unsubscribe_from(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
        core.quit()  # stop study
      
win.close() # close window
Eyetracker.unsubscribe_from(tr.EYETRACKER_GAZE_DATA, gaze_data_callback) # unsubscribe eyetracking
core.quit() # stop study
```